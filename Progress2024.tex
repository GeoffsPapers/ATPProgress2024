\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{multicol}
\usepackage{array}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}}
\setlength{\tabcolsep}{3pt}

\renewcommand{\floatpagefraction}{0.9}
\renewcommand{\textfloatsep}{2.0ex}
\renewcommand{\dbltextfloatsep}{2.0ex}

\newenvironment{packed_itemize}{
\vspace*{-0.5em}
\begin{itemize}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{itemize}}

\renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}

\title{Empirical Evidence of Progress in ATP}
\titlerunning{Progress in ATP}

\author{
Geoff Sutcliffe\inst{1}\orcidID{0000-0001-9120-3927}
\and
Christian Suttner\inst{2}
\and \\
C. Raymond Perrault\inst{3}\orcidID{0009-0001-1178-343X}
\and \\
Lars Kotthoff\inst{4}\orcidID{0000-0003-4635-6873}
\and \\
Zain~Khalid\inst{1}\orcidID{0009-0001-2063-6933}
}
\authorrunning{G. Sutcliffe, et al.}
\institute{University of Miami, USA \\
\email{geoff@cs.miami.edu},
\email{zsk17@miami.edu}
\and
Deceased
\and 
SRI International, USA \\
\email{ray.perrault@sri.com}
\and 
University of Wyoming, USA \\
\email{larsko@uwyo.edu}
}

\maketitle
%--------------------------------------------------------------------------------------------------
\begin{abstract}
The TPTP World is a well established infrastructure that supports research, development, and 
deployment of Automated Theorem Proving (ATP) systems
Two major components of the TPTP World are the TPTP problem library and the TSTP solution library.
Data in the TPTP and TSTP has been used to assess progress in ATP in the last decade, in
terms of first solutions of problems that are of direct interest to humans, the fraction of
problems solved, decreasing problem difficulty ratings, and temporal Shapley values.
The analyses show WHAT?

\keywords{Automated Theorem Proving \and Empirical Evaluation \and Progress in ATP}
\end{abstract}
%--------------------------------------------------------------------------------------------------
\section{Introduction}
\label{Introduction}

The TPTP World \cite{Sut17} is a well established infrastructure that supports research, 
development, and deployment of Automated Theorem Proving (ATP) systems.
The TPTP World includes the TPTP problem library,
% \cite{Sut09}, 
the TSTP solution library,
% \cite{Sut10}, 
standards for writing ATP problems and reporting ATP solutions,
% \cite{SS+06,Sut08-KEAPPA}, 
tools and services for processing ATP problems and solutions,
% \cite{Sut10}, 
and it supports the CADE ATP System Competition (CASC).
% \cite{Sut16}.
Various parts of the TPTP World have been deployed in a range of applications,
in both academia and industry.
The web page \href{https://www.tptp.org}{\tt www.tptp.org} provides access to all 
components.

At two points in the past, the TPTP World has been used as the basis for evaluating progress
in ATP \cite{SFS01,SSP21}.
In both cases the core idea was to examine the difficulty ratings of the problems in the TPTP 
problem library, which are computed wrt performance data from ATP systems.
The ratings are updated in each TPTP release, so that as time goes by and ATP systems improve 
the ratings decrease
As the problems are unchanged (they are not actually getting easier) this is evidence that 
the state-of-the-art in ATP systems is improving.
This paper provides an update on progress in ATP based on the data in the TPTP release v8.2.0.
The analysis process has been refined to take into account anomalies caused by ATP systems
becoming (un)available over the years.

The use of system performance data to evaluate a field of endeavour is common.
In the realm of logic-based systems, examples include
the various compititions for logic-based systems, e.g., CASC \cite{Sut16}, SAT Competition 
\cite{JL+12}, SMT-COMP \cite{BdS05}, ASP Competition \cite{CI+12} (\cite{BB+19} provides an 
overview of these and other competitions),
the Technical Performance chapter of Stanford University's AI Index Annual Report \cite{MF+23},
the use of Shapley values to evaluate algorithmic improvements in SAT solving \cite{FK+16,KF+19},
and
an examination of progress in SAT solving comparing algorithmic and hardware advances \cite{FHS20}.
A general examination of the requirements for such benchmarking is provided by \cite{BLW19}.
In all cases the common features of the evaluation are (i)~the ability of systems solve given test
problems, and (ii)~the resources required by the systems to solve those test problem.
In order for the results to be relevant, the test problems must be representative of the problems
the systems will face in research or industrial applications, and the resource measurements must
be appropriate for the availability and demands of the applications.

It is important to differentiate between evaluations at instances in time, such as provided by
competitions, and evaluation over time.
At instances of time the test problems used for evaluation, the systems being evaluated, and
the hardware/software platform used are static.
That provides a clean basis for detailed comparison between systems.
In contrast, evaluation over time is complicated by changing test problems, changing systems,
and changing hardware/software.
This dynamic evaluation environment requires additional control to provide meaningful results.

\paragraph{Paper structure:}
Section~\ref{TPTP} provides ...
Section~\ref{TSTP} provides ...
Section~\ref{AnalysisProcesses} provides ...
Section~\ref{Evidence} provides ...
Section~\ref{Conclusion} concludes. 

%--------------------------------------------------------------------------------------------------
\section{The TPTP Problem Library}
\label{TPTP}

The core of the TPTP World is the TPTP problem library \cite{Sut09}; it is the de facto standard 
set of test problems for classical logic ATP systems.
The problems can be browsed online\footnote{%
\href{https://www.tptp.org/cgi-bin/SeeTPTP?Category=Problems}
{\tt www.tptp.org/cgi-bin/SeeTPTP?Category=Problems}}
and documentation is available\footnote{%
\href{https://www.tptp.org/cgi-bin/SeeTPTP?Category=Documents\&File=OverallSynopsis}
{\tt www.tptp.org/cgi-bin/SeeTPTP?Category=Documents\&File=OverallSynopsis}}.
Each release of the problem library is identified by a number in the form 
$version$.$edition$.$patch$.
The $version$ is incremented when important new features are added,
the $edition$ is incremented when new problems are added, and
the $patch$ level is incremented when errors have been corrected.
The current release is v8.2.0.
Section~\ref{TSTP} explains why the analyses of progress presented in this paper start at
TPTP~v6.2.0.
Table~\ref{TPTPReleases} gives some summary data about the TPTP releases from v6.2.0 to v8.2.0;
the acronyms for problem types are listed in Section~\ref{SPCs}.

\begin{table}[htb]
\begin{center}
\setlength{\tabcolsep}{4pt}
\begin{tabular}{ll|l|r}
Release & Date     & Changes                                 & Size \\
\hline
v6.2.0  & 14/07/15 & TSTP data from StarExec                 &   20654 \\
v6.3.0  & 28/11/15 & New TFO problems with arithmetic        &   20762 \\
v6.4.0  & 31/06/16 & New problems                            &   20897 \\
v7.0.0  & 24/07/17 & First TH1 problems                      &   21851 \\
v7.1.0  & 06/03/18 & TXF syntax specified, no problems       &   22011 \\
v7.2.0  & 10/07/18 & New problems                            &   22026 \\
v7.3.0  & 02/08/19 & New problems                            &   22686 \\
v7.4.0  & 10/07/20 & New problems                            &   23291 \\
v7.5.0  & 13/07/21 & New problems                            &   24098 \\
v8.0.0  & 19/04/22 & First TXF problems                      &   24785 \\
v8.1.0  & 30/07/22 & New problems                            &   25257 \\
v8.2.0  & 13/06/23 & New problems                            &   25474 \\
\end{tabular}
\end{center}
\caption{Overview of TPTP releases}
\label{TPTPReleases}
\end{table}

The TPTP problem files present the logical formulae in a format that is both human and machine 
readable, and additionally provide useful information for users.
Each problem file has a header section (as comments) that file contains information for users
in four parts:
the first part identifies and describes the problem;
the second part provides information about occurrences of the problem in the literature and 
elsewhere;
the third part provides semantic and syntactic characteristics of the problem;
the last part contains comments and bugfix information.
The third part is most relevant to this work. 
It contains the problem's SZS status \cite{SZS03} that provides the semantic status of the 
problem, e.g., if it is a {\tt Theorem}, a {\tt Satisfiable} set of formulae, a problem whose 
status is {\tt Unknown}, etc.
It also contains statistics about the problem's syntax, e.g., the number of formulae, the 
number of predicate and functions symbols, the use of connectives, etc.
The SZS status and the syntactic characteristics are used to form the Specialist Problem Class
of the problem.

%--------------------------------------------------------------------------------------------------
\subsection{Specialist Problem Classes}
\label{SPCs}

The problems in the library are divided into Specialist Problem Classes (SPCs) - classes of 
homogeneous problems with the same recognizable logical, language, and syntactic characteristics.
% SPCs added in v4.1.0 15/06/10
Evaluation of ATP systems within SPCs makes it possible to say which systems work well for what 
types of problems. 
The appropriate level of subdivision for SPCs is that at which less subdivision would merge 
SPCs for which ATP systems have distinguishable behaviour, and at which further subdivision
would unnecessarily split an SPC for which ATP systems have reasonably homogeneous behaviour.
Empirically, this is ensured by examining the patterns of system performance across the 
problems in each SPC. 
For example, the separation of ``essentially propositional'' problems was motivated by observing 
that SPASS (WA+99) performed differently on the ALC problems in the SYN domain of the TPTP.
A data-driven test of the homogeneity can also provide assurance that the SPCs are
appropriate \cite{FS02}.

The characteristics used to define the SPCs in TPTP v8.2.0 are~\ldots
\begin{enumerate}
\item TPTP language: \\
      {\tt CNF} -- Clause Normal Form,
      {\tt FOF} -- First-Order Form, \\
      {\tt TF0} -- Typed Monomorphic First-order form, \\
      {\tt TF1} -- Typed Polymorphic First-order form , \\
      {\tt TX0} -- Typed Monomorphic eXtended First-order form, \\
      {\tt TX1} -- Typed Polymorphic eXtended First-order form, \\
      {\tt TH0} -- Typed Monomorphic Higher-order form, \\
      {\tt TH1} -- Typed Polymorphic Higher-order form.
\item SZS status: \\
      {\tt THM} (includes {\tt CAX}) -- Theorem (includes Contradictory AXioms), \\
      {\tt CSA} -- CounterSAtisfiable,
      {\tt UNS} -- UNSatisfiable, \\
      {\tt SAT} -- SATisfiable,
      {\tt OPN} -- OPeN, 
      {\tt UNK} -- UNKown.
\item Order (for {\tt CNF} and {\tt FOF}): \\
      {\tt RFO} -- Real First-Order (not thought to be reducaible to~\ldots),\\
      {\tt EPR} -- Effectively PRopositional (can be reduced to~\ldots),\\
      {\tt PRP} -- PRoPositional.
\item Equality: \\
      {\tt NEQ} -- No EQuality,
      {\tt EQU} -- EQUality (some or pure), \\
      {\tt SEQ} -- Some (not pure) EQUality, \\
      {\tt PEQ} -- Pure EQUality (for {\tt CNF} qualified as either~\ldots),\\
      {\tt UEQ} -- Unit EQUality or
      {\tt NUE} -- Non-Unit Equality.
\item Hornness (for {\tt CNF}): \\
      {\tt HRN} -- HoRN,
      {\tt NHN} -- Non-HorN.
\item Arithmetic (for {\tt T*} languages): \\
      {\tt NAR} -- No ARithmetic,
      {\tt ARI} -- ARIthmetic.
\end{enumerate}

Using these characteristics 223 SPCs are defined in TPTP v8.2.0.
Some examples are:
{\tt CNF\_SAT\_EPR\_PEQ\_UEQ} -- clause normal form satisfiable clauses that are effectively
propositional (known to be reducible to propositional logic), have purely equality literals
in unit equality clauses;
{\tt FOF\_THM\_RFO\_SEQ} -- first-order theorems that are ``really first-order'' (not believed
to be reducible to propositional logic) and contain some (not only) equality;
{\tt TF0\_THM\_NEQ\_ARI} -- typed monomorphic first-order theorems that have no equality but do
include arithmetic.
Combinations of SPCs are written using UNIX globbing, e.g., {\tt TH0\_CSA\_*\_NAR} is the
combination of {\tt TH0\_CSA\_EQU\_NAR} and {\tt TH0\_CSA\_NEQ\_NAR} -- typed monomorphic 
higher-order countersatisfiable (non-theorem) problems either with or without equality.

The SPCs are used when computing the TPTP problem ratings.

%--------------------------------------------------------------------------------------------------
\subsection{TPTP Problem Ratings}
\label{Ratings}

Each TPTP problem has a difficulty rating that provides a well-defined measure of how difficult 
the problem is for current ATP systems \cite{SS01}.
The ratings are based on performance data in the TSTP (see Section~\ref{TSTP}), and are updated
in each TPTP edition.
Rating is done separately for each SPC, to provide a rating that compares problems with the
same characteristics.
A partial order between systems is determined according to whether or not a system solves a strict 
superset of the problems solved by another system. 
If a strict superset is solved, the first system is said to {\em subsume} the second system. 
The union of the problems solved by the non-subsumed systems defines the state-of-the-art -- all 
the problems that are solved by any system. 
The fraction of non-subsumed systems that fail on a problem is the difficulty rating for the 
problem. 
Problems that are solved by all of the non-subsumed systems get a rating of 0.00 (``easy'');
problems that are solved by some of the non-subsumed systems get a rating between 
0.00 and 1.00 (``difficult''); 
problems that are solved by none of the non-subsumed systems get a rating of 1.00 (``unsolved'').

%--------------------------------------------------------------------------------------------------
\section{The TSTP Solution Library}
\label{TSTP}

The complement of the problem library is the TSTP solution library \cite{Sut07-CSR,Sut10}.
% Started as the results collection for the TPTP circa 1997, became the TSTP circa 2002.
The TSTP is built by running all the ATP systems that are available in the TPTP World on
all the problems in the TPTP problem library.
The ATP systems have come from a range of sources:
some were developed many years ago, and are no longer distributed;
some are the most recent available, taken either from the systems’ web sites or from the most 
recent edition of the CADE ATP System Competition (CASC) \cite{Sut16}.
At the time of writing this paper, the TSTP contained the results of running 87 ATP systems and 
system variants on all the problems in the TPTP that they could attempt.
% (therefore, e.g., systems that do model finding for FOF are not run on THF problems).
This has produced 1091026 runs, of which 432718 (39.6\%) solved the problem.

% User hardware at first, moved to my servers around 2010, then StarExec Iowa \cite{SST14} in 2012,
Prior to 2010 the data in the TSTP came from results submitted by ATP system developers who
performed testing on their own hardware.
From 2010 to 2013 the data was generated on the TPTP World servers at the University of Miami.
Since 2014 the ATP systems have been run on StarExec \cite{SST14}, initially on the StarExec
Iowa cluster, and since 2018 on the StarExec Miami cluster.
This has provided stable platforms that produce reliably consistent and comparable data in
the TSTP.
For that reason the analyses presented in Section~\ref{AnalysisProcesses} start at TPTP v6.2.0, 
which was released in July 2015, i.e., the problem ratings were based on data produced on the 
StarExec computers.

The StarExec Iowa computers have an ZZZZZZZZZZZZ Add Version
octa-core Intel(R) Xeon(R) E5-2667 v4 CPU run at 2.10 GHz,
128 GiB memory,
and the CentOS Linux release 7.4.1708 (Core) operating system
Linux kernel 3.10.0-693.el7.x86\_64.
The StarExec Miami computers have an
octa-core Intel(R) Xeon(R) E5-2667 v4 CPU run at 2.10 GHz,
128 GiB memory,
and the CentOS Linux release 7.4.1708 (Core) operating system
Linux kernel 3.10.0-693.el7.x86\_64.
One ATP system is run on one CPU at a time, with a 300s CPU time limit and a 129GiB memory
limit (see Section~\ref{ResourceLimits}).
StarExec provides a consistent level of hardware - not much difference between Iowa and Miami.

One use of the TSTP is for ATP system developers to examine solutions to problems and thus 
understand how they can be solved, leading to improvements to their own systems. 
The use considered here is as the basis for TPTP problem ratings.

%--------------------------------------------------------------------------------------------------
\subsection{Resource Limits}
\label{ResourceLimits}

Analysis shows that increasing resource limits does not significantly affect which problems 
are solved by each ATP system. 
Figure\ref{PPPPlot} illustrates this point.
Figure\ref{PPPPlot} plots the CPU times taken by several contemporary ATP systems to solve the 
TPTP problems for the SPCs {\tt FOF\_THM\_RFO\_*}, in increasing order of time taken. 
The data was taken from the TSTP, i.e., using the StarExec Miami computers.
The relevant feature of these plots is that each system has a point at which the time taken to 
find solutions starts to increase dramatically. 
This point is called the system's Peter Principle \cite{PH69} Point (PPP), as it is the point at 
which the system has reached its level of incompetence. 
Evidently a linear increase in the computational resources beyond the PPP would not lead to the 
solution of significantly more problems. 
The PPP thus defines a ``realistic computational resource limit'' for the system. 
From an ATP perspective, the PPP is the point at which the ATP system gets lost in its quickly 
growing search space. 
Even though there may be enough memory to represent the search space at the PPP, the system is 
largely unable to find a solution within the space. 
The point thus also defines a ``realistic memory resource limit''. 
Therefore, provided that enough CPU time and memory are allowed for an ATP system to pass its 
PPP, a usefully accurate measure of what problems it can solve within realistic resource limits 
is achieved.
The performance data in the TSTP is produced with adequate resource limits.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.75\textwidth]{Plots/FOF_THM_RFO_PPP/FOF_THM_RFO_PPP}
\vspace*{-1em}
\caption{CPU times for {\tt FOF\_THM\_RFO\_*}}
\label{PPPPlot}
\end{figure}

%--------------------------------------------------------------------------------------------------
\section{Analysis Processes}
\label{AnalysisProcesses}

%--------------------------------------------------------------------------------------------------
\subsection{Analysis Data}
\label{AnalysisData}

The analyses performed use the TPTP problem ratings, and historical data about which
ATP systems solved which problems in each TPTP release provided in the 
{\tt ProblemAndSolutionStatistics} file that accompanies each TPTP release.
As explained in Section~\ref{TSTP}, TSTP data starting from TPTP v6.2.0 in July 2015 has been
used, taking snapshots at each TPTP edition up to v8.2.0.

Before analysis the rating data is cleaned in two steps:

\paragraph{Cleaning for the Past:}
Problems are added to the TPTP in each release, and corresponding TSTP data is generated using 
the {\em currently available} ATP systems.
As it is not possible to run all {\em previously available} ATP systems on new problems when they 
are added to the TPTP, it is simply {\em assumed} that if a new problem is unsolved by the 
current ATP systems when it is added to the TPTP, then it would have been unsolved by 
previously available ATP systems.
The rating data is thus augmented for problems added after v6.2.0 with an initial rating of 1.00 
(unsolved), by setting the rating to 1.00 in prior TPTP releases back to v6.2.0.
% Additionally, problems added in v6.3.0 in November 2015 with an initial rating less than
% 1.00 are also retrospectively ``added'' to v6.2.0, because the set of ATP systems used for
% building the TSTP did not change in that time period.
Other problems added after v6.2.0 with an initial rating less than 1.00 are ignored, because 
it is unknown whether or not the previously available systems would have solved them.

\paragraph{Cleaning for Change:}
A counterintuitive feature of an individual problem's difficulty ratings is that they sometimes 
increase with time, because they are computed wrt the TSTP data from all the currently available
ATP systems.
Increases are caused by new ATP systems becoming available.
The TSTP data of a new system that is not subsumed (no other system solves all the problems 
that the new system solves) is used in the rating process.
The ratings of problems that the new system solves decrease, but at the same time the ratings of
problems that the new system does not solve increase.\footnote{%
Conversely, if a system that was not subsumed becomes unavailable, it does not contribute TSTP
data for new problems.
The new problems have higher ratings than they would have had if the system had remained
available.
Since the TSTP data started being generated on StarExec, this has been a rare occurrence, e.g.,
Isabelle ran fine on StarExec Iowa, but did not port to StarExec Miami in 2018.
This has not materially impacted the analyses of progress.}
An increase of a problem's rating is counterintuitive because the problem has not changed, and 
it can still be solved by the previously available systems.
This anomaly was noted in prior analysis \cite{Sut17} where it was noted: ``The ratings generally 
show a downward trend - there has been progress!'', but ``ratings can also increase when data 
from new systems is added to the TSTP.''
This anomaly is resolved by tracking each problem's rating forwards in time from the point 
that it was added to the TPTP.
If at any release the rating increases, for analysis the rating is reduced to its prior
lower rating value.

%--------------------------------------------------------------------------------------------------
\subsection{Coherent SPC Sets}
\label{SPCSets}

Three of the analyses (as described in Section~\ref{AnalysisTypes}) look at the data for a set
of problems.
In order for such analyses to be meaningful it is necessary that the problems are reasonably
coherent, so that the ATP systems whose TSTP data is used in the analysis are, at least
in principle, able to attempt the problems.
The basis for such sets are the SPCs (see Section~\ref{SPCs}).
The SPCs provide a quite fine-grained partitioning of the TPTP problems, and individual SPCs
are intrinsically coherent.
Additionally, some SPCs that that capture compatible problem characteristic can be merged
to form a coherent set.

The coherent SPC sets used for the analyses are listed in Table~\ref{SPCSetsTable}.
The first column lists the SPCs that are in the set, using the abbreviations given in 
Section~\ref{SPCs}.
The second column describes the set, explaining why it is coherent.
The third column gives the number of problems after the data cleaning, and the original
total number of problems in the set in TPTP v8.2.0.
Some noteworthy exclusions are:
Typed extended first-order problems because they were added to the TPTP only in v8.0.0;
Typed polymorphic first-order and higher-order problems excluded because too few systems are 
capable of attempting the problems and generating the necessary TSTP data;
Some SPCs that have too few problems.

\renewcommand{\arraystretch}{1.5}
\begin{table*}[h!]
\center
\begin{tabular}{p{3.5cm}|p{7cm}|R{1cm}}
\hline
SPCs & Description & Size \\
\hline
{\tt CNF\_UNS\_RFO\_NEQ\_*}\enspace$\cup$ {\tt CNF\_UNS\_RFO\_SEQ\_*}\enspace$\cup$
{\tt CNF\_UNS\_RFO\_PEQ\_NUE} &
Unsatisfiable sets of really first-order Horn and non-Horn clauses that are not unit equality.
& NNNN 4445 \\  % 1115 + 2785 + 545 = 4445 problems in v8.2.0
{\tt CNF\_UNS\_RFO\_PEQ\_UEQ} &
Unsatisfiable sets of really-first-order unit equality clauses.
& NNNN 1140 \\
{\tt CNF\_SAT\_RFO\_*} &
Ssatisfiable sets of really-first-order Horn and non-Horn clauses.
& NNNN 1044 \\
{\tt CNF\_*\_EPR\_*} &
Unsatisfiable and satisfiable sets of effectively propositional Horn and non-Horn clauses.
Un/Satisfiable sets are coherent because effectively propositional sets are decidable.
& NNNN 897 \\
{\tt FOF\_THM\_RFO\_*} &
Really first-order theorems, with and without equality.
& NNNN 7204 \\
{\tt FOF\_CSA\_RFO\_*}\enspace$\cup$ {\tt FOF\_SAT\_RFO\_*} &
Really first-order non-theorems and satisfiable sets, with and without equality.
& NNNN 1329 \\ % 707 + 322 = 1329 problems.
{\tt TF0\_THM\_*\_NAR} &
Typed monomorphic first-order theorems, with and without equality, without arithmetic.
& NNNN 400 \\
{\tt TF0\_THM\_*\_ARI} &
Typed monomorphic first-order theorems, with and without equality, with arithmetic.
& NNNN 1176 \\
{\tt TF0\_CSA\_*\_NAR}\enspace$\cup$ {\tt TF0\_SAT\_*\_NAR} &
Typed monomorphic first-order non-theorems and satisfiable sets, with and without equality, without 
arithmetic.
& NNNN 155 \\ % 35 + 120  TOO FEW?
{\tt TH0\_THM\_*\_NAR} &
Typed monomorphic higher-order theorems, with and without equality, without arithmetic.
& NNNN 3189 \\
\hline
\end{tabular}
\vspace*{0.5em}
\caption{Coherent SPC sets}
\label{SPCSetsTable}
\end{table*}

%--------------------------------------------------------------------------------------------------
\subsection{Four Analyses}
\label{AnalysisTypes}

The cleaned rating and the historical data is used for four analyses of progress.
Individual problem ratings are used for the first analysis.
The other three analyses use the coherent SPC set described in Section~\ref{SPCSets}.

\paragraph{First Solutions:}
ATP has been successfully applied in a range of academic applications.
Arguably the last use comes from the ``hammers'' \cite{BK+16} associated with Interactive 
Theorem Proving (ITP) systems, e.g., Sledghammer \cite{PB10} for Isabelle \cite{NPW02}, 
HOLyHammer \cite{KU14} for HOL Light \cite{Har09} and HOL4 \cite{SN08}, 
MizAR \cite{KU15-M40} for Mizar \cite{GKN10}.
In these applications the problems being solved are not of direct interest to humans,
who are focussed on the larger task being addressed in the ITP system.
In contrast, the use of ATP by practitioners attacking problems are less common, and even
less successful.
The sparsity makes successes particularly noteworthy, e.g., the solution of the Robbins
problem by Bill McCune using the ATP system EQP \cite{McC97}.
In general, the first solutions of problems that are of direct interest to humans are
indications of progress.
These are identifiable by (i)~the rating decreasing from 1.00, and (ii)~some evidence that the 
problem is of direct interest to at least some humans.

\paragraph{Fraction Solved:}
The first overall analysis looks at the fraction of problems solved in each TPTP release --
this is the approach used in \cite{SSP21}.
It is simply the fraction of problems with rating less than 1.00.
This analysis uses the cleaned ratings data, averaged over the problems in each coherent SPC set.
% CS OBJECTS In order for this analysis to be meaningful 

\paragraph{Decreasing Ratings:}
A more fine-grained analysis is provided by the decrease in problem difficulty ratings over
time \cite{SFS01}.
This analysis also uses the cleaned ratings data, averaged over the problems in each coherent 
SPC set.

\paragraph{Shapley Values:}
Another quite fine-grained analysis is provided through the use of temporal Shapley values 
\cite{KF+19}.
In a first phase the problems solved by a State-of-the-Art (SotA) system for a TPTP release is 
defined by the union of the problems solved by all the individual ATP systems used for the TSTP 
at the time.
The SotA systems in the TPTP releases are treated as a portfolio of systems to be analysed, and 
the Shapley analysis shows which SotA systems made strong contributions to progress, i.e., it
identifies the TPTP releases where strong progress was evident.
Following that, plain (non-temporal) Shapley analysis \cite{FK+16} is used to identify which
of the individual ATP systems made strong contributions to those strong SotA systems.
This analysis uses the historical solution data within each coherent SPC set.

%% \begin{enumerate}
%% \item Extract all data from TSTP, starting from v6.2.0, per above.
%% \item Fill right for problems added after v6.2.0 if their rating started at 1.00. 
%% %      If the rating started below 1.00, that assumes that earlier systems would have been
%% %      equally able to solve it, which might be kind to those systems.
%% %      The result is less apparent progress before then.
%% \item Fill left for missing data
%%       \begin{itemize}
%%       \item Do not allow a problem to become more difficult.
%%       \end{itemize}
%% \item Remove problems with missing ratings
%% \item Extract ratings for a chosen set of SPCs 
%% \item Compute summary data
%%       \begin{itemize}
%%       \item Number of problem rows
%%       \item Average rating
%%       \item Number of problem rows with rating 0.00 to 0.99
%%       \item Fraction of problem rows with rating 0.00 to 0.99
%%       \item Number of problem rows with rating 0.00
%%       \item Fraction of problem rows with rating 0.00
%%       \item Number of problem rows with rating 0.01 to 0.99
%%       \item Fraction of problem rows with rating 0.01 to 0.99
%%       \item Number of problem rows with rating 1.00
%%       \item Fraction of problem rows with rating 1.00
%%       \end{itemize}
%% \item Plot by date
%%       \begin{itemize}
%%       \item Fraction of problem rows with rating 0.00 to 0.99
%%       \item Average rating
%%       % \item Fraction of problem rows with rating 0.00
%%       % \item Fraction of problem rows with rating 0.01 to 0.99
%%       % \item Fraction of problem rows with rating 1.00
%%       \item Temporal Shapley value
%%       \end{itemize}
%% \end{enumerate}

%--------------------------------------------------------------------------------------------------
\section{Evidence of Progress}
\label{Evidence}

\begin{figure}[ht!]
\centering
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt CNF\_UNS\_RFO\_\{NEQ\_*,SEQ\_*,PEQ\_NUE\}}}
  \label{Plot_CNF_UNS}
\end{minipage}
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt CNF\_UNS\_RFO\_PEQ\_UEQ}}
  \label{Plot_CNF_UEQ}
\end{minipage}
\end{figure}
\begin{figure}[ht!]
\centering
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt CNF\_SAT\_RFO\_*}}
  \label{Plot_CNF_SAT}
\end{minipage}
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt CNF\_*\_EPR\_*}}
  \label{Plot_CNF_EPR}
\end{minipage}
\end{figure}

Commentary for CNF.

\begin{figure}[ht!]
\centering
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt FOF\_THM\_RFO\_*}}
  \label{Plot_FOF_THM}
\end{minipage}
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt FOF\_\{CSA,SAT\}\_RFO\_*}}
  \label{Plot_FOF_SAT}
\end{minipage}
\end{figure}

Commentary for FOF.

\begin{figure}[ht!]
\centering
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt TF0\_THM\_*\_NAR}}
  \label{Plot_TF0_THM_NAR}
\end{minipage}
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt TF0\_THM\_*\_ARI}}
  \label{Plot_TF0_THM_ARI}
\end{minipage}
\end{figure}
\begin{figure}[ht!]
\centering
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt TF0\_\{CSA,SAT\}\_*\_NAR}}
  \label{Plot_TF0_SAT_NAR}
\end{minipage}
\begin{minipage}[t]{.49\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Plots/GNUPlots/TestData.pdf}
  \vspace*{-2em}
  \caption{{\tt TH0\_THM\_*\_NAR}}
  \label{Plot_TH0_THM_NAR}
\end{minipage}
\end{figure}

Commentary for TF0 and TH0.

%--------------------------------------------------------------------------------------------------
\section{Conclusion}
\label{Conclusion}

This paper 

Ongoing and future work includes~\ldots

%--------------------------------------------------------------------------------------------------
\bibliographystyle{splncs04}
\bibliography{Bibliography}
%--------------------------------------------------------------------------------------------------
\end{document}
